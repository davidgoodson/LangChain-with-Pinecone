{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d420f-c1d4-4375-93dd-895640775b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredEPubLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "\n",
    "import pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\") #langchain searches for this key and loads it automatically\n",
    "os.environ['PINECONE_API_KEY'] = os.getenv(\"PINECONE_API_KEY\") #langchain searches for this key and loads it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e06128-4e47-413e-91ed-c63013544376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load PDF File\n",
    "loader = PyPDFLoader('./assets/srp-covid-19-6month.pdf')\n",
    "pdf = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b3fb5-71f8-4e82-baee-f565147b02d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pinecone index name\n",
    "index_name = \"rag-project\"\n",
    "\n",
    "# embeddings using OpenAI \"text-embedding-ada-002\"\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Create the vector store\n",
    "vectorstore = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name, \n",
    "    embedding=embed_model, \n",
    "    text_key=\"text\", # the key containing the text chunks in the meta data\n",
    "    namespace=\"all-users\", # optional if you didn't set a name space\n",
    "    pool_threads=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ef107",
   "metadata": {},
   "source": [
    "### Using a Simple QA Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbaf3a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'When was thef first covid case?',\n",
       " 'result': 'The first known cases of COVID-19 were reported in December 2019 in Wuhan, China.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creat the QA Chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "query = \"When was thef first covid case?\"\n",
    "\n",
    "qa.invoke(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74708917",
   "metadata": {},
   "source": [
    "### Using a Retrieval Chain With A Custom Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9525b0d",
   "metadata": {},
   "source": [
    "##### *Using OllamaLLM llama2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd5b66e7-e624-4a04-ac44-78ee3900c574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'When was thef first covid case?', 'context': [Document(id='6', metadata={}, page_content='1 2\\n \\nCOVID-19: February–June progress report\\n  \\n    COVID-19: February–June progress report\\nFOREWORD\\nMore than six months since the world first learned of what we now call COVID-19, the time is \\nright to take stock of where we are in the outbreak and how the world has responded. \\nThe pandemic has already taken a terrible toll. By the end of June 2020, WHO had received \\nreports of almost 10 million cases and half a million lives lost. The pandemic continues to \\naccelerate; at the current rate, cases are doubling around every six weeks. We are facing a \\nmoment of great danger. We can only prevail if we stand together in global solidarity. \\nCOVID-19 will always take the path of least resistance. We know that when countries take \\na comprehensive approach based on fundamental public health measures and a whole-\\nof-society approach, COVID-19 can be brought under control, saving lives and enabling'), Document(id='187', metadata={}, page_content='43 44\\n \\nCOVID-19: February–June progress report\\n  \\n    COVID-19: February–June progress report\\nIn focus: Africa COVID-19 hackathon\\nIn the first week of April 2020, the WHO Regional Office \\nfor Africa hosted its first Hackathon, bringing together 100 \\nleading innovators from across sub-Saharan Africa in a \\nbid to pioneer creative local solutions to the COVID-19 \\npandemic and address critical gaps in the regional \\nresponse. \\nThrough a facilitated process, participants were tasked with \\ndeveloping innovative and scalable approaches and tools \\naligned with one of the pillars of the COVID-19 country \\nresponse strategy, including coordination; surveillance; \\nrisk communication and community engagement; points \\nof entry; laboratory; infection prevention and control; case \\nmanagement and continuity of essential health services; \\nand operational and logistics support. Based on the \\nadjudication process by experts, three innovations have \\nsince received seed funding amounting to US$ 22 500'), Document(id='115', metadata={}, page_content='29 30\\n \\nCOVID-19: February–June progress report\\n  \\n    COVID-19: February–June progress report\\nSurveillance, rapid-response teams and case \\ninvestigation, and national laboratories\\nStopping the spread of COVID-19 requires finding and testing \\nall suspected cases so that confirmed cases are promptly \\nand effectively isolated and receive appropriate care, and the \\nclose contacts of all confirmed cases are rapidly identified so \\nthat they can be quarantined and medically monitored for the \\n14-day incubation period of the virus. To achieve this, countries \\nand communities must fundamentally increase their capacity to \\nidentify suspected cases of COVID-19 in the general population \\nquickly based on the onset of signs or symptoms. WHO has \\nworked closely with national authorities to ensure that all countries \\nhave access to diagnostic testing as part of surveillance strategies \\nbased on WHO guidance. By the end of June, 99% of countries'), Document(id='164', metadata={}, page_content='39 40\\n \\nCOVID-19: February–June progress report\\n  \\n    COVID-19: February–June progress report\\nThe landmark collaborative initiative was launched at an event \\nco-hosted by WHO, the President of France, the President \\nof the European Commission, and the Bill & Melinda Gates \\nFoundation. The event was joined by the UN Secretary-\\nGeneral, the AU Commission Chairperson, the G20 President, \\nheads of state of France, South Africa, Germany, Vietnam, \\nCosta Rica, Italy, Rwanda, Norway, Spain, Malaysia and the \\nUK (represented by the First Secretary of State), together with \\nhealth leaders from the Coalition for Epidemic Preparedness \\nInnovations (CEPI), GAVI, the Vaccine Alliance, the Global \\nFund, UNITAID, the Wellcome Trust, the International Red \\nCross and Red Crescent Movement (IFRC), the International \\nFederation of Pharmaceutical Manufacturers (IFPMA), the \\nDeveloping Countries Vaccine Manufacturers’ Network \\n(DCVMN), and the International Generic and Biosimilar')], 'answer': \"I don't know.\"}\n"
     ]
    }
   ],
   "source": [
    "# Import Ollama LLM\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Load Ollama LAMA2 LLM Model\n",
    "llm = OllamaLLM(model='llama2')\n",
    "\n",
    "# Import Ollama LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Load Ollama LAMA2 LLM Model\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# Design Chat Prompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an AI assistant. Use only the provided context to answer the question.\n",
    "    If the answer is unknown, say \"I don't know.\"\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    Question: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create Stuff Document Chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "\n",
    "# Retrival\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever = vectorstore.as_retriever(), combine_docs_chain=document_chain)\n",
    "\n",
    "query = \"When was thef first covid case?\"\n",
    "response = retrieval_chain.invoke({\"input\": query})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d7431",
   "metadata": {},
   "source": [
    "##### *Using OpenAI's GPT-4o*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ChaptOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Load GPT-4o Model\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# Design Chat Prompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an AI assistant. Use only the provided context to answer the question.\n",
    "    If the answer is unknown, say \"I don't know.\"\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    Question: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create Stuff Document Chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "\n",
    "# Retrival\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever = vectorstore.as_retriever(), combine_docs_chain=document_chain)\n",
    "\n",
    "query = \"When was thef first covid case?\"\n",
    "response = retrieval_chain.invoke({\"input\": query})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca09d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
